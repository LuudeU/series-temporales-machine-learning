{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pequeño tutorial de Pytorch\n",
    "\n",
    "En este notebook vamos a desarrollar algunos aspectos básicos de PyTorch para implementar modelos sencillos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en Numpy, donde tenemos un objeto fundamental (ndarray), pytorch tiene su propio objeto, que es muy similar a un array de Numpy, pero con mayores funcionalidades, fundamentalmente relacionadas al producto de tensores y calculo de gradientes (autograd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[[-0.1932, -1.3645],\n",
      "         [-1.3809,  1.4023],\n",
      "         [-1.3404, -0.9427]],\n",
      "\n",
      "        [[-0.4223,  0.2423],\n",
      "         [ 0.6098,  0.0603],\n",
      "         [-1.0045, -0.1565]],\n",
      "\n",
      "        [[-1.8231, -1.7659],\n",
      "         [-1.2167,  0.0636],\n",
      "         [-1.5977, -0.0681]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3,2) # Tensor de ceros\n",
    "b = torch.randn(3,3,2) # tensor de numeros aleatorios\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([[1,2],[3,4],[5,6]]) # tensor a partir de una lista\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5991, -1.7046, -0.6497],\n",
      "         [-1.0011, -0.4523,  0.7368]],\n",
      "\n",
      "        [[-0.3121,  0.1646, -1.1698],\n",
      "         [ 0.7263,  2.0821,  0.0850]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "a = rng.normal(size=(2,2,3))\n",
    "b = torch.from_numpy(a)\n",
    "print(b)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las operaciones tipicas de numpy se pueden utilizar en pytorch: manejo de indices, operaciones aritmeticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5991, -1.7046, -0.6497],\n",
      "         [-1.0011, -0.4523,  0.7368]],\n",
      "\n",
      "        [[-0.3121,  0.1646, -1.1698],\n",
      "         [ 0.7263,  2.0821,  0.0850]]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5991, -1.7046, -0.6497],\n",
       "        [-1.0011, -0.4523,  0.7368],\n",
       "        [-0.3121,  0.1646, -1.1698],\n",
       "        [ 0.7263,  2.0821,  0.0850]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En vez de reshape, se utiliza el metodo view\n",
    "\n",
    "b.view(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5991, -1.7046],\n",
       "        [-0.6497, -1.0011],\n",
       "        [-0.4523,  0.7368],\n",
       "        [-0.3121,  0.1646],\n",
       "        [-1.1698,  0.7263],\n",
       "        [ 2.0821,  0.0850]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# al igual que en Numpy, -1 es un comodin para redimensionar\n",
    "b.view(6,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5991, -1.7046, -0.6497, -1.0011, -0.4523,  0.7368, -0.3121,  0.1646,\n",
       "        -1.1698,  0.7263,  2.0821,  0.0850], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.59905006, -1.70464776, -0.64974363],\n",
       "        [-1.00111894, -0.45233454,  0.73684236]],\n",
       "\n",
       "       [[-0.31211146,  0.16459671, -1.16975174],\n",
       "        [ 0.72630958,  2.08212998,  0.08497032]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para hacer un cast de un tensor en un ndarray, basta con utilizar el metodo numpy()\n",
    "\n",
    "b.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd - Grafos computacionales y diferenciacion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(1., requires_grad= True) # requires_grad significa que guarda y calcula el grafo computacional\n",
    "b = torch.tensor(2.,requires_grad= True)\n",
    "\n",
    "f = a + b  # Tensor con la suma\n",
    "\n",
    "c = torch.tensor(3., requires_grad= True)\n",
    "\n",
    "g = f*c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.backward() # el metodo backward recorre el grafo hacia atras encontrando todas las derivadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAs derivadas se calculan llamando simplemente llamando al atributo grad\n",
    "\n",
    "$$\n",
    "\\frac{dg}{da} = \\frac{dg}{df}\\frac{df}{da},\\ \\frac{dg}{db} = \\frac{dg}{df}\\frac{df}{db}, \\frac{dg}{dc} = \\frac{dg}{dc} \n",
    "$$\n",
    "$$\n",
    "\\frac{dg}{da} = c \\times 1,\\ \\frac{dg}{db} = c \\times 1, \\frac{dg}{dc} = f \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.) tensor(3.) tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "print(a.grad, b.grad, c.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUS  - manejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para saber si tenemos una GPU disponible\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# En caso de tener una GPU disponible, basta con alojar los tensores en la GPU y operar con ellos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Codes/series-temporales-machine-learning/STenv/lib/python3.10/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# En caso de tener una GPU disponible, basta con alojar los tensores en la GPU y operar con ellos\n",
    "a = torch.randn(1000,1000).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# una buena practica es definir una variable que identifique el tipo de procesador y utilice la gpu por defecto\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# y utilizar el device \n",
    "a = torch.tensor(1., requires_grad= True, device= device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
